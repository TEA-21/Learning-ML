{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3138,"status":"ok","timestamp":1750243993710,"user":{"displayName":"Taanush abraham","userId":"16497560746847074205"},"user_tz":-330},"id":"bST7Y9kF0s0f","outputId":"291f9035-87a1-42b3-acb4-20679501a5b3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'OMRChecker'...\n","remote: Enumerating objects: 5974, done.\u001b[K\n","remote: Counting objects: 100% (1029/1029), done.\u001b[K\n","remote: Compressing objects: 100% (373/373), done.\u001b[K\n","remote: Total 5974 (delta 760), reused 690 (delta 652), pack-reused 4945 (from 2)\u001b[K\n","Receiving objects: 100% (5974/5974), 39.16 MiB | 24.00 MiB/s, done.\n","Resolving deltas: 100% (3881/3881), done.\n"]}],"source":["!git clone https://github.com/Udayraj123/OMRChecker\n","!cd OMRChecker/"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11294,"status":"ok","timestamp":1750243990568,"user":{"displayName":"Taanush abraham","userId":"16497560746847074205"},"user_tz":-330},"id":"cOwqlxu7SrZP","outputId":"82b75a2f-7fd6-46ef-e268-a3154648d0f5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n","Collecting pytesseract\n","  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python-headless) (2.0.2)\n","Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (24.2)\n","Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (11.2.1)\n","Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n","Installing collected packages: pytesseract\n","Successfully installed pytesseract-0.3.13\n"]}],"source":["!pip install opencv-python-headless pytesseract"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8ajpzHlu7fjc"},"outputs":[],"source":["def find_custom_markers(image, thresh_size, aspect_ratio_tolerance):\n","    # Step 1: Convert to Grayscale and Blur\n","    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n","\n","    cv2_imshow(\"1. Grayscale and Blurred Image\", blurred)\n","    cv2.waitKey(0)\n","\n","    # Step 2: Adaptive Thresholding\n","    thresh = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n","                                   cv2.THRESH_BINARY_INV, thresh_size, 4)\n","\n","    cv2_imshow(\"2. Adaptive Threshold Result\", thresh)\n","    cv2.waitKey(0)\n","\n","    # Step 3: Find Contours\n","    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","\n","    # Visualize all detected contours (before any filtering)\n","    image_all_contours = image.copy()\n","    cv2.drawContours(image_all_contours, contours, -1, (0, 255, 0), 2)\n","    cv2_imshow(f\"3. All {len(contours)} Detected Contours\", image_all_contours)\n","    cv2.waitKey(0)\n","\n","    valid_marker_corners = []\n","    potential_marker_areas = []\n","    potential_markers=[]\n","\n","    # --- First Pass: Collect potential marker areas to calculate median ---\n","    # This step doesn't filter by aspect ratio or convexity yet, only by approxPolyDP length and raw area.\n","    image_pass1_filtered_contours = image.copy()\n","    pass1_contours_count = 0\n","\n","    for i, contour in enumerate(contours):\n","        perimeter = cv2.arcLength(contour, True)\n","        approx = cv2.approxPolyDP(contour, 0.03 * perimeter, True)\n","\n","        # Filter by approximate number of vertices\n","        if len(approx) >= 3 and len(approx) <= 5: # Keep shapes that are somewhat rectangular/polygonal\n","            area = cv2.contourArea(contour)\n","            if 500 < area < 500000: # Broad area filter\n","                 potential_marker_areas.append(area)\n","                 potential_markers.append(contour)\n","                 cv2.drawContours(image_pass1_filtered_contours, [contour], -1, (0, 255, 255), 2) # Yellow\n","                 pass1_contours_count += 1\n","\n","    cv2_imshow(f\"4. Contours Passing Initial Approx/Area Filter ({pass1_contours_count} found)\", image_pass1_filtered_contours)\n","    cv2.waitKey(0)\n","\n","    if not potential_marker_areas:\n","        print(\"No potential marker areas found in the first pass.\")\n","        cv2.destroyAllWindows()\n","        return []\n","\n","\n","    expected_pattern_template = np.array([\n","        [0, 1, 0],\n","        [1, 0, 1],\n","        [0, 1, 0]\n","    ], dtype=np.uint8)\n","\n","    marker_warp_size = 90\n","    max_sad_tolerance = 4\n","\n","    # --- Second Pass: Apply more rigorous filters and pattern matching ---\n","    image_pass2_filtered_contours = image.copy()\n","    pass2_contours_count = 0\n","\n","    for i, contour in enumerate(potential_markers):\n","        area = cv2.contourArea(contour)\n","\n","        perimeter = cv2.arcLength(contour, True)\n","        approx = cv2.approxPolyDP(contour, 0.03 * perimeter, True)\n","\n","        # Filter by number of vertices (again, as some might have been too complex in first pass)\n","        if not (len(approx) >= 3 and len(approx) <= 5):\n","            continue\n","\n","        # Filter by convexity\n","        if not cv2.isContourConvex(approx):\n","            print(f\"Contour {i}: Not convex. Skipping.\")\n","            continue\n","\n","        x, y, w, h = cv2.boundingRect(approx)\n","        aspect_ratio = float(w) / h\n","\n","        # Filter by aspect ratio\n","        if not (1 - aspect_ratio_tolerance <= aspect_ratio <= 1 + aspect_ratio_tolerance):\n","            print(f\"Contour {i}: Aspect ratio {aspect_ratio:.2f} out of tolerance. Skipping.\")\n","            continue\n","\n","        # At this point, the contour is a strong candidate for an outer marker. Draw it in blue.\n","        cv2.drawContours(image_pass2_filtered_contours, [contour], -1, (255, 0, 0), 2) # Blue\n","        pass2_contours_count += 1\n","\n","        # Determine points for perspective transform\n","        if len(approx) != 4:\n","            # If not exactly 4, use bounding box corners for warp (less accurate but fallback)\n","            marker_pts = np.float32([[x, y], [x + w, y], [x + w, y + h], [x, y + h]])\n","            print(f\"Contour {i}: Approximated contour has {len(approx)} vertices. Using bounding box for warp.\")\n","        else:\n","            marker_pts = approx.reshape(4, 2)\n","            print(f\"Contour {i}: Approximated contour has 4 vertices. Using approx for warp.\")\n","\n","        ordered_pts = order_points(marker_pts)\n","\n","        # Visualize the ordered points on the original image\n","        img_temp_corners = image.copy()\n","        for k, pt in enumerate(ordered_pts):\n","            cv2.circle(img_temp_corners, (int(pt[0]), int(pt[1])), 5, (0, 0, 255), -1) # Red circles\n","            cv2.putText(img_temp_corners, str(k), (int(pt[0]) + 10, int(pt[1]) + 10),\n","                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n","        # cv2_imshow(f\"5. Contour {i} (Blue) & Ordered Points (Red)\", img_temp_corners)\n","        cv2.waitKey(0)\n","\n","\n","        dst_pts = np.float32([\n","            [0, 0],\n","            [marker_warp_size - 1, 0],\n","            [marker_warp_size - 1, marker_warp_size - 1],\n","            [0, marker_warp_size - 1]\n","        ])\n","\n","        M_warp = cv2.getPerspectiveTransform(ordered_pts, dst_pts)\n","        warped_marker_gray = cv2.warpPerspective(gray, M_warp, (marker_warp_size, marker_warp_size))\n","\n","        cv2_imshow(f\"6. Warped Marker (Grayscale) for Contour {i}\", warped_marker_gray)\n","        cv2.waitKey(0)\n","\n","        _, warped_marker_thresh = cv2.threshold(warped_marker_gray, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n","\n","        cv2_imshow(f\"7. Warped Marker (Thresholded) for Contour {i}\", warped_marker_thresh)\n","        cv2.waitKey(0)\n","\n","        cell_size = marker_warp_size // 3\n","        current_marker_pattern = np.zeros((3, 3), dtype=np.uint8)\n","\n","        # Visualize the 3x3 grid and extracted pattern\n","        warped_marker_pattern_debug = cv2.cvtColor(warped_marker_thresh, cv2.COLOR_GRAY2BGR)\n","        for row in range(3):\n","            for col in range(3):\n","                cell_roi = warped_marker_thresh[row * cell_size:(row + 1) * cell_size,\n","                                                col * cell_size:(col + 1) * cell_size]\n","                avg_intensity = np.mean(cell_roi)\n","\n","                # Draw grid lines\n","                cv2.rectangle(warped_marker_pattern_debug,\n","                              (col * cell_size, row * cell_size),\n","                              ((col + 1) * cell_size - 1, (row + 1) * cell_size - 1),\n","                              (0, 255, 0), 1)\n","\n","                if avg_intensity < 50:\n","                    current_marker_pattern[row, col] = 0\n","                    cv2.putText(warped_marker_pattern_debug, \"0\",\n","                                (col * cell_size + cell_size // 2 - 10, row * cell_size + cell_size // 2 + 10),\n","                                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n","                elif avg_intensity > 102:\n","                    current_marker_pattern[row, col] = 1\n","                    cv2.putText(warped_marker_pattern_debug, \"1\",\n","                                (col * cell_size + cell_size // 2 - 10, row * cell_size + cell_size // 2 + 10),\n","                                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n","\n","        sad_score = np.sum(np.abs(current_marker_pattern - expected_pattern_template))\n","\n","        if sad_score <= max_sad_tolerance:\n","            valid_marker_corners.append((sad_score, ordered_pts))\n","            print(f\"Contour {i}: Extracted Pattern:\\n{current_marker_pattern}\")\n","            cv2_imshow(f\"8. Warped Marker with Extracted Pattern for Contour {i}\", warped_marker_pattern_debug)\n","            print(f\"Contour {i}: SAD Score = {sad_score}. Max tolerance = {max_sad_tolerance}\")\n","            cv2.waitKey(0)\n","            # Draw the final valid marker in magenta\n","            cv2.drawContours(image, [ordered_pts.reshape((-1, 1, 2)).astype(np.int32)], -1, (255, 0, 255), 3)\n","            print(f\"Contour {i}: Valid marker found!\")\n","        else:\n","            print(f\"Contour {i}: Pattern mismatch. SAD score too high.\")\n","\n","    cv2_imshow(f\"9. Final Valid Markers Detected (Magenta)\", image)\n","    cv2.waitKey(0)\n","    cv2.destroyAllWindows() # Close all windows at the end\n","    # Sort candidates by SAD score (lower is better)\n","    valid_marker_corners.sort(key=lambda x: x[0])\n","    # Take the top 4 (or fewer if not enough)\n","    top_4_markers = []\n","    for marker_pts in valid_marker_corners[:4]:\n","        top_4_markers.append(marker_pts[1])\n","        cv2.drawContours(image, [marker_pts[1].reshape((-1, 1, 2)).astype(np.int32)], -1, (255, 0, 255), 3)\n","    return top_4_markers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M8EFUnpSNjHm"},"outputs":[],"source":["import re\n","import os\n","import cv2\n","import math\n","import json\n","import time\n","import numpy as np\n","import pytesseract\n","from IPython.display import display_markdown, Markdown\n","import copy\n","\n","def order_points(pts):\n","    rect = np.zeros((4, 2), dtype=\"float32\")\n","    s = pts.sum(axis=1)\n","    rect[0] = pts[np.argmin(s)]\n","    rect[2] = pts[np.argmax(s)]\n","    diff = np.diff(pts, axis=1)\n","    rect[1] = pts[np.argmin(diff)]\n","    rect[3] = pts[np.argmax(diff)]\n","    return rect\n","\n","def find_custom_markers(image, thresh_size, aspect_ratio_tolerance = 1):\n","    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n","\n","    thresh = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n","                                   cv2.THRESH_BINARY_INV, thresh_size, 4)\n","\n","    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","\n","    valid_markers = []\n","    potential_marker_areas = []\n","    potential_markers=[]\n","\n","    for i, contour in enumerate(contours):\n","        perimeter = cv2.arcLength(contour, True)\n","        approx = cv2.approxPolyDP(contour, 0.03 * perimeter, True)\n","\n","        # Filter by approximate number of vertices\n","        if len(approx) >= 3 and len(approx) <= 5: # Keep shapes that are somewhat rectangular/polygonal\n","            area = cv2.contourArea(contour)\n","            if 500 < area < 500000: # Broad area filter\n","                 potential_marker_areas.append(area)\n","                 potential_markers.append(contour)\n","\n","    if not potential_marker_areas:\n","        print(\"No potential marker areas found in the first pass.\")\n","        cv2.destroyAllWindows()\n","        return []\n","\n","    expected_pattern_template = np.array([\n","        [0, 1, 0],\n","        [1, 0, 1],\n","        [0, 1, 0]\n","    ], dtype=np.uint8)\n","\n","    marker_warp_size = 90\n","    max_sad_tolerance = 4\n","\n","    for i, contour in enumerate(potential_markers):\n","        area = cv2.contourArea(contour)\n","\n","        perimeter = cv2.arcLength(contour, True)\n","        approx = cv2.approxPolyDP(contour, 0.03 * perimeter, True)\n","\n","        if not (len(approx) >= 3 and len(approx) <= 5):\n","            continue\n","\n","        if not cv2.isContourConvex(approx):\n","            continue\n","        x, y, w, h = cv2.boundingRect(approx)\n","        aspect_ratio = float(w) / h\n","\n","        if not (1 - aspect_ratio_tolerance <= aspect_ratio <= 1 + aspect_ratio_tolerance):\n","            continue\n","\n","        if len(approx) != 4:\n","            marker_pts = np.float32([[x, y], [x + w, y], [x + w, y + h], [x, y + h]])\n","        else:\n","            marker_pts = approx.reshape(4, 2)\n","\n","        ordered_pts = order_points(marker_pts)\n","\n","        dst_pts = np.float32([\n","            [0, 0],\n","            [marker_warp_size - 1, 0],\n","            [marker_warp_size - 1, marker_warp_size - 1],\n","            [0, marker_warp_size - 1]\n","        ])\n","\n","        M_warp = cv2.getPerspectiveTransform(ordered_pts, dst_pts)\n","        warped_marker_gray = cv2.warpPerspective(gray, M_warp, (marker_warp_size, marker_warp_size))\n","\n","        _, warped_marker_thresh = cv2.threshold(warped_marker_gray, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n","\n","        cell_size = marker_warp_size // 3\n","        current_marker_pattern = np.zeros((3, 3), dtype=np.uint8)\n","\n","        for row in range(3):\n","            for col in range(3):\n","                cell_roi = warped_marker_thresh[row * cell_size:(row + 1) * cell_size,\n","                                                 col * cell_size:(col + 1) * cell_size]\n","                avg_intensity = np.mean(cell_roi)\n","                if avg_intensity < 70:\n","                    current_marker_pattern[row, col] = 0\n","                elif avg_intensity > 102:\n","                    current_marker_pattern[row, col] = 1\n","                else:\n","                    current_marker_pattern[row, col] = 2\n","\n","        sad_score = np.sum(np.abs(current_marker_pattern - expected_pattern_template))\n","\n","        if sad_score <= max_sad_tolerance:\n","            valid_markers.append((sad_score, ordered_pts))\n","            print(f\"Contour {i}: Valid marker candidate found with SAD score {sad_score}!\")\n","            print(f\"Contour {i}: Extracted Pattern:\\n{current_marker_pattern}\")\n","            print(f\"Contour {i}: SAD Score = {sad_score}. Max tolerance = {max_sad_tolerance}\")\n","\n","    # Take the top 4 (or fewer if not enough)\n","    top_4_markers = [markers[1] for markers in valid_markers if markers[0] == 0]\n","    if len(top_4_markers) >= 4:\n","        return top_4_markers\n","    else:\n","        # Sort candidates by SAD score (lower is better)\n","        valid_markers.sort(key=lambda x: x[0])\n","        top_4_markers = []\n","        for marker_pts in valid_markers[:4]:\n","            top_4_markers.append(marker_pts[1])\n","            cv2.drawContours(image, [marker_pts[1].reshape((-1, 1, 2)).astype(np.int32)], -1, (255, 0, 255), 3)\n","        return top_4_markers\n","\n","def deskew_document(image_path, thresh_size, aspect_ratio_tolerance, osd):\n","    img = cv2.imread(image_path)\n","    if img is None:\n","        print(f\"Error: Could not load image {image_path}. Please check the path.\")\n","        return None\n","\n","    # Store original dimensions for comparison\n","    original_height, original_width = img.shape[:2]\n","\n","    all_markers = find_custom_markers(img, thresh_size, aspect_ratio_tolerance = 1)\n","\n","    if len(all_markers) < 4:\n","        print(f\"Error: Only {len(all_markers)} valid fiducial markers found. Need 4 for accurate deskewing.\")\n","        print(\"Please ensure all four corner markers are clearly visible and distinct in the image.\")\n","        return None\n","\n","    all_marker_points = np.vstack(all_markers)\n","    source_points = order_points(all_marker_points)\n","\n","    (tl, tr, br, bl) = source_points\n","\n","    widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\n","    widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n","    maxWidth = max(int(widthA), int(widthB))\n","\n","    heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\n","    heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\n","    maxHeight = max(int(heightA), int(heightB))\n","\n","    min_expected_dim = max(original_width, original_height) * 0.5\n","    max_expected_dim = max(original_width, original_height) * 2.0\n","\n","    if not (min_expected_dim < maxWidth < max_expected_dim and \\\n","            min_expected_dim < maxHeight < max_expected_dim):\n","        print(f\"Warning: Calculated deskewed dimensions ({maxWidth}x{maxHeight}) seem unusual compared to original ({original_width}x{original_height}).\")\n","        print(\"This often indicates issues with fiducial marker detection. Please ensure the markers are clearly visible and properly formed.\")\n","        return None\n","\n","    destination_points = np.float32([\n","        [0, 0],\n","        [maxWidth - 1, 0],\n","        [maxWidth - 1, maxHeight - 1],\n","        [0, maxHeight - 1]\n","    ])\n","\n","    M = cv2.getPerspectiveTransform(source_points, destination_points)\n","    warped_img = cv2.warpPerspective(img, M, (maxWidth, maxHeight))\n","\n","    if osd == True and warped_img.shape[1] > warped_img.shape[0]:\n","        warped_img = cv2.rotate(warped_img, cv2.ROTATE_90_CLOCKWISE)\n","        try:\n","            warped_gray = cv2.cvtColor(warped_img, cv2.COLOR_BGR2GRAY)\n","            osd = pytesseract.image_to_osd(warped_gray)\n","\n","            rotation_angle = 0\n","            for line in osd.split('\\n'):\n","                if line.startswith('Rotate:'):\n","                    try:\n","                        rotation_angle = int(line.split(': ')[1])\n","                        break\n","                    except ValueError:\n","                        pass\n","\n","            if rotation_angle == 90:\n","                warped_img = cv2.rotate(warped_img, cv2.ROTATE_90_CLOCKWISE)\n","            elif rotation_angle == 180:\n","                warped_img = cv2.rotate(warped_img, cv2.ROTATE_180)\n","            elif rotation_angle == 270:\n","                warped_img = cv2.rotate(warped_img, cv2.ROTATE_90_COUNTERCLOCKWISE)\n","\n","        except pytesseract.TesseractNotFoundError:\n","            print(\"Tesseract is not installed or not in your PATH. Cannot correct for upside-down orientation.\")\n","        except Exception as e:\n","            print(f\"An error occurred during OCR orientation detection: {e}\")\n","\n","    return warped_img\n","\n","def cv2_imshow(title, image):\n","    try:\n","        from google.colab.patches import cv2_imshow as colab_cv2_imshow\n","        print(title)\n","        colab_cv2_imshow(image)\n","    except ImportError:\n","        cv2.imshow(title, image)\n","\n","def preprocess_image(image):\n","    if image is None:\n","        raise ValueError(\"Image is None.\")\n","    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n","    _, thresh = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n","    return image, thresh\n","\n","\n","def get_contour_center(contour):\n","    M = cv2.moments(contour)\n","    if M[\"m00\"] != 0:\n","        cx = int(M[\"m10\"] / M[\"m00\"])\n","        cy = int(M[\"m01\"] / M[\"m00\"])\n","        return (cx, cy)\n","    return None\n","\n","\n","def remove_duplicate_contours(contours, min_distance_factor=0.5):\n","    if not contours:\n","        return []\n","\n","    contour_data = []\n","    all_areas = []\n","    for contour in contours:\n","        center = get_contour_center(contour)\n","        if center is not None:\n","            area = cv2.contourArea(contour)\n","            contour_data.append((contour, center, area))\n","            all_areas.append(area)\n","\n","    if not all_areas:\n","        return []\n","\n","    median_area = np.median(all_areas)\n","    median_radius = np.sqrt(median_area / np.pi)\n","\n","    min_distance = median_radius * min_distance_factor\n","    min_distance = max(10, min_distance)\n","\n","    contour_data.sort(key=lambda x: x[2], reverse=True)\n","\n","    filtered_contours = []\n","    used_centers = []\n","\n","    for contour, center, area in contour_data:\n","        is_duplicate = False\n","        for used_center in used_centers:\n","            distance = np.sqrt((center[0] - used_center[0]) ** 2 + (center[1] - used_center[1]) ** 2)\n","            if distance < min_distance:\n","                is_duplicate = True\n","                break\n","\n","        if not is_duplicate:\n","            filtered_contours.append(contour)\n","            used_centers.append(center)\n","\n","    return filtered_contours\n","\n","\n","def find_bubble_contours(thresh_img):\n","    contours, _ = cv2.findContours(thresh_img.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n","\n","    potential_bubble_areas = []\n","    pre_filtered_contours = []\n","\n","    for contour in contours:\n","        area = cv2.contourArea(contour)\n","        if area < 50 or area > 10000:\n","            continue\n","\n","        perimeter = cv2.arcLength(contour, True)\n","        if perimeter == 0:\n","            continue\n","        circularity = 4 * np.pi * (area / (perimeter * perimeter))\n","\n","        x, y, w, h = cv2.boundingRect(contour)\n","        aspect_ratio = float(w) / h\n","\n","        if 0.65 < circularity < 1.3 and 0.8 < aspect_ratio < 1.3:\n","            extent = area / (w * h)\n","            if extent < 0.8:\n","                pre_filtered_contours.append(contour)\n","                potential_bubble_areas.append(area)\n","\n","    if not potential_bubble_areas:\n","        print(\"No potential bubble areas found in initial pass.\")\n","        return []\n","\n","    median_area = np.median(potential_bubble_areas)\n","\n","    dynamic_min_area = median_area * 0.8\n","    dynamic_max_area = median_area * 1.6\n","\n","    final_bubble_contours = []\n","    for contour in pre_filtered_contours:\n","        area = cv2.contourArea(contour)\n","        if dynamic_min_area < area < dynamic_max_area:\n","            final_bubble_contours.append(contour)\n","\n","    return remove_duplicate_contours(final_bubble_contours, min_distance_factor=0.8)\n","\n","\n","def load_template(template_path):\n","    try:\n","        with open(template_path, 'r') as f:\n","            template = json.load(f)\n","        print(f\"‚úÖ Template loaded: {len(template['regions'])} regions found\")\n","        return template\n","    except Exception as e:\n","        print(f\"‚ùå Error loading template: {e}\")\n","        return None\n","\n","\n","def is_point_in_region(point, region_coords):\n","    x, y = point\n","    rx, ry, rw, rh = region_coords['x'], region_coords['y'], region_coords['width'], region_coords['height']\n","    buffer = 5\n","    return (rx - buffer) <= x <= (rx + rw + buffer) and (ry - buffer) <= y <= (ry + rh + buffer)\n","\n","\n","def map_contours_to_grid(contours_in_region, region): ## Dynamic Mapping of Rows and Cols\n","    if not contours_in_region:\n","        return []\n","\n","    coords = region['coordinates']\n","    grid = region['grid']\n","    rows_expected, cols_expected = grid['rows'], grid['cols']\n","\n","    contours_in_region.sort(key=lambda c: get_contour_center(c)[1] if get_contour_center(c) else float('inf'))\n","\n","    mapped_contours = []\n","    row_groups = []\n","\n","    if not contours_in_region:\n","        return []\n","\n","    if rows_expected > 0 and coords['height'] > 0:\n","        avg_row_height = coords['height'] / rows_expected\n","        row_detection_threshold = avg_row_height * 0.4\n","    else:\n","        row_detection_threshold = 15\n","\n","    current_row_group = []\n","    last_center_y = -1\n","\n","    for contour in contours_in_region:\n","        center = get_contour_center(contour)\n","        if center is None:\n","            continue\n","\n","        if not current_row_group:\n","            current_row_group.append(contour)\n","            last_center_y = center[1]\n","        else:\n","            if abs(center[1] - last_center_y) > row_detection_threshold:\n","                row_groups.append(current_row_group)\n","                current_row_group = [contour]\n","            else:\n","                current_row_group.append(contour)\n","            last_center_y = center[1]\n","\n","    if current_row_group:\n","        row_groups.append(current_row_group)\n","\n","    for r_idx, row_group in enumerate(row_groups):\n","        row_group.sort(key=lambda c: get_contour_center(c)[0] if get_contour_center(c) else float('inf'))\n","\n","        for c_idx, contour in enumerate(row_group):\n","            center = get_contour_center(contour)\n","            if center is None:\n","                continue\n","\n","            mapped_contours.append({\n","                'contour': contour,\n","                'center': center,\n","                'grid_pos': (r_idx, c_idx),\n","                'row': r_idx,\n","                'col': c_idx\n","            })\n","\n","    mapped_contours.sort(key=lambda x: (x['row'], x['col']))\n","\n","    return mapped_contours\n","\n","\n","def classify_bubbles(image, contours, fill_threshold=0.5):\n","    results = []\n","    if len(image.shape) == 3:\n","        gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","    else:\n","        gray_image = image\n","\n","    for contour in contours:\n","        x, y, w, h = cv2.boundingRect(contour)\n","\n","        roi_x = x + int(w * 0.25)\n","        roi_y = y + int(h * 0.25)\n","        roi_w = int(w * 0.5)\n","        roi_h = int(h * 0.5)\n","\n","        roi_x = max(0, roi_x)\n","        roi_y = max(0, roi_y)\n","        roi_w = min(roi_w, gray_image.shape[1] - roi_x)\n","        roi_h = min(roi_h, gray_image.shape[0] - roi_y)\n","\n","        if roi_w <= 0 or roi_h <= 0:\n","            is_filled = False\n","        else:\n","            central_roi = gray_image[roi_y : roi_y + roi_h, roi_x : roi_x + roi_w]\n","            mean_val = np.mean(central_roi)\n","            is_filled = mean_val < fill_threshold * 255\n","        results.append((contour, is_filled))\n","    return results\n","\n","def generate_labels_and_decode(template, all_contours, gray_image):\n","    results = {}\n","    labeled_contours = []\n","\n","    for region in template['regions']:\n","        region_name = region['name']\n","        region_type = region['type']\n","        coords = region['coordinates']\n","        grid = region['grid']\n","        row_labels = region.get('row_labels', [])\n","        col_labels = region.get('col_labels', [])\n","\n","        contours_in_region = [c for c in all_contours if is_point_in_region(get_contour_center(c), coords)]\n","        if not contours_in_region:\n","            print(f\"No bubbles found in region: {region_name}\")\n","            continue\n","\n","        mapped_contours = map_contours_to_grid(contours_in_region, region)\n","\n","        classified_contours_only = [mc['contour'] for mc in mapped_contours]\n","        classified_results = classify_bubbles(gray_image, classified_contours_only)\n","\n","        region_data = {}\n","\n","        if len(mapped_contours) != len(classified_results):\n","            print(f\"Warning: Mismatch in lengths of mapped_contours ({len(mapped_contours)}) and classified_results ({len(classified_results)}) for region {region_name}. Skipping this region.\")\n","            continue\n","\n","        for i, mapped_contour in enumerate(mapped_contours):\n","            contour_obj = mapped_contour['contour']\n","            is_filled = classified_results[i][1]\n","            row, col = mapped_contour['row'], mapped_contour['col']\n","\n","            label_prefix = f\"{region_name}_R{row}_C{col}\"\n","\n","            if region_type == 'student_id':\n","                if col < grid['cols'] and row < len(row_labels):\n","                    label_prefix = f\"{region_name}_D{col+1}_{row_labels[row]}\"\n","                    if is_filled:\n","                        region_data.setdefault(f\"digit_{col+1}\", []).append(row_labels[row])\n","\n","            elif region_type == 'true_false':\n","                question_num = row + 1\n","                if col < len(col_labels):\n","                    label_prefix = f\"{region_name}_Q{question_num}_{col_labels[col]}\"\n","                    if is_filled:\n","                        region_data.setdefault(f\"question_{question_num}\", []).append(col_labels[col])\n","\n","            elif region_type == 'multiple_choice':\n","                question_offset = region.get('question_offset', 0)\n","                question_num = question_offset + row + 1\n","\n","                if col < len(col_labels):\n","                    label_prefix = f\"{region_name}_{question_num}{col_labels[col]}\"\n","                    if is_filled:\n","                        region_data.setdefault(f\"question_{question_num}\", []).append(col_labels[col])\n","\n","            elif region_type == 'custom':\n","                if grid['cols'] > 1 and row < len(row_labels) and all(l.isdigit() for l in row_labels):\n","                    label_prefix = f\"{region_name}_D{col+1}_{row_labels[row]}\"\n","                    if is_filled:\n","                        region_data.setdefault(f\"digit_{col+1}\", []).append(row_labels[row])\n","                elif grid['cols'] == 1 and row < len(row_labels):\n","                    label_prefix = f\"{region_name}_{row_labels[row]}\"\n","                    if is_filled:\n","                        region_data.setdefault(f\"field_{row_labels[row]}\", []).append(row_labels[row])\n","                elif row < len(row_labels) and col < len(col_labels):\n","                    label_prefix = f\"{region_name}_R{row_labels[row]}_C{col_labels[col]}\"\n","                    if is_filled:\n","                        region_data.setdefault(f\"field_R{row_labels[row]}\", []).append(col_labels[col])\n","                else:\n","                    label_prefix = f\"{region_name}_Pos{col+1}x{row+1}\"\n","                    if is_filled:\n","                        region_data.setdefault(f\"field_R{row+1}\", []).append(f\"C{col+1}\")\n","\n","            labeled_contours.append({\n","                'contour': contour_obj,\n","                'label': label_prefix,\n","                'is_filled': is_filled,\n","                'region': region_name,\n","                'center': mapped_contour['center']\n","            })\n","\n","        if region_type == 'student_id' or (region_type == 'custom' and grid['cols'] > 1 and all(l.isdigit() for l in row_labels)):\n","            decoded_id = []\n","            for i in range(grid['cols']):\n","                digit_values = region_data.get(f\"digit_{i+1}\", [])\n","                if len(digit_values) == 1:\n","                    decoded_id.append(digit_values[0])\n","                elif len(digit_values) > 1:\n","                    decoded_id.append('X')\n","                    print(f\"Warning: Multiple bubbles filled for {region_name} digit {i+1}. Marked as 'X'.\")\n","                else:\n","                    decoded_id.append('_')\n","            results[region_name.lower().replace(' ', '_')] = ''.join(str(d) for d in decoded_id)\n","\n","        elif region_type in ['true_false', 'multiple_choice']:\n","            decoded_answers = {}\n","            start_q = region.get('question_offset', 0) + 1 if region_type == 'multiple_choice' else 1\n","            for i in range(grid['rows']):\n","                q_num = start_q + i\n","                answers_for_q = region_data.get(f\"question_{q_num}\", [])\n","                if len(answers_for_q) == 1:\n","                    decoded_answers[str(q_num)] = answers_for_q[0]\n","                elif len(answers_for_q) > 1:\n","                    decoded_answers[str(q_num)] = 'X'\n","                    print(f\"Warning: Multiple bubbles filled for {region_name} question {q_num}. Marked as 'X'.\")\n","                else:\n","                    decoded_answers[str(q_num)] = None\n","            results[region_name.lower().replace(' ', '_')] = decoded_answers\n","\n","        elif region_type == 'custom':\n","            results[region_name.lower().replace(' ', '_')] = region_data\n","\n","    return labeled_contours, results\n","\n","\n","def draw_labeled_results(original, labeled_contours):\n","    output_image = original.copy()\n","    for item in labeled_contours:\n","        contour = item['contour']\n","        label = item['label']\n","        is_filled = item['is_filled']\n","        center = item['center']\n","\n","        color = (0, 255, 0) if is_filled else (0, 0, 255)\n","\n","        cv2.drawContours(output_image, [contour], -1, color, 2)\n","\n","        cv2.circle(output_image, center, 3, color, -1)\n","\n","        display_label = label.split('_')[-1]\n","        cv2.putText(output_image, display_label, (center[0] + 5, center[1] - 5),\n","                    cv2.FONT_HERSHEY_SIMPLEX, 0.4, color, 1)\n","    return output_image\n","\n","\n","def process_omr_with_template(deskewed_img, template_path):\n","    template = load_template(template_path)\n","    if not template:\n","        return None\n","    if deskewed_img is None:\n","        return {\"error\": \"Kindly check uploaded image, Make sure its clear and Markers are visible\"}\n","    original, thresh = preprocess_image(deskewed_img)\n","    gray = cv2.cvtColor(original, cv2.COLOR_BGR2GRAY)\n","\n","    template_markers_json = template['metadata']['marker_positions']\n","    template_tl = [template_markers_json['top_left']['x'], template_markers_json['top_left']['y']]\n","    template_tr = [template_markers_json['top_right']['x'], template_markers_json['top_right']['y']]\n","    template_br = [template_markers_json['bottom_right']['x'], template_markers_json['bottom_right']['y']]\n","    template_bl = [template_markers_json['bottom_left']['x'], template_markers_json['bottom_left']['y']]\n","\n","    src_template_pts = np.float32([template_tl, template_tr, template_br, template_bl])\n","    src_template_pts = order_points(src_template_pts)\n","\n","    actual_height, actual_width = original.shape[:2]\n","\n","    dst_deskewed_pts = np.float32([\n","        [0, 0],\n","        [actual_width - 1, 0],\n","        [actual_width - 1, actual_height - 1],\n","        [0, actual_height - 1]\n","    ])\n","\n","    M = cv2.getPerspectiveTransform(src_template_pts, dst_deskewed_pts)\n","\n","    for region in template['regions']:\n","        coords = region['coordinates']\n","\n","        region_corners = np.float32([\n","            [coords['x'], coords['y']],\n","            [coords['x'] + coords['width'], coords['y']],\n","            [coords['x'] + coords['width'], coords['y'] + coords['height']],\n","            [coords['x'], coords['y'] + coords['height']]\n","        ]).reshape(-1, 1, 2)\n","\n","        transformed_corners = cv2.perspectiveTransform(region_corners, M).reshape(-1, 2)\n","\n","        region['coordinates']['x'] = int(np.min(transformed_corners[:, 0]))\n","        region['coordinates']['y'] = int(np.min(transformed_corners[:, 1]))\n","        region['coordinates']['width'] = int(np.max(transformed_corners[:, 0]) - region['coordinates']['x'])\n","        region['coordinates']['height'] = int(np.max(transformed_corners[:, 1]) - region['coordinates']['y'])\n","\n","    bubbles = find_bubble_contours(thresh)\n","    print(f\"Found {len(bubbles)} potential bubbles after dynamic filtering.\")\n","\n","    labeled_contours, decoded_data = generate_labels_and_decode(template, bubbles, gray)\n","\n","    output_image = draw_labeled_results(original.copy(), labeled_contours)\n","    return output_image, decoded_data\n","\n","def decode_omr(input_omr, omr_template, thresh_size, aspect_ratio_tolerance, check_orientation):\n","    deskewed_document = deskew_document(input_omr, thresh_size, aspect_ratio_tolerance, check_orientation)\n","\n","    if deskewed_document is not None:\n","        output_image, decoded_data = process_omr_with_template(deskewed_document, omr_template)\n","\n","        if decoded_data:\n","            return output_image, decoded_data\n","        else:\n","            return None, None\n","    else:\n","        return None, None\n","\n","\n","def grade_omr_sheet(solution_json, answer_json, if_correct=4, if_wrong=-1):\n","\n","    results = {\n","        'student_info': {},\n","        'section_wise_marks': {},\n","        'question_wise_analysis': {},\n","        'total_marks': 0,\n","        'total_questions': 0,\n","        'correct_answers': 0,\n","        'wrong_answers': 0,\n","        'unattempted': 0,\n","        'multiple_marked': 0,\n","        'custom_fields': {},\n","        'summary': {}\n","    }\n","\n","    # Store sections in order for adjacent checking\n","    section_order = []\n","    section_question_ranges = {}\n","\n","    for section_name, section_data in answer_json.items():\n","\n","        if isinstance(section_data, str):\n","            if 'student' in section_name.lower() or 'id' in section_name.lower() or 'roll' in section_name.lower():\n","                results['student_info'][section_name] = section_data\n","            else:\n","                results['custom_fields'][section_name] = section_data\n","            continue\n","\n","        elif isinstance(section_data, dict):\n","            keys = list(section_data.keys())\n","\n","            if keys and all(k.isdigit() for k in keys):\n","                section_order.append(section_name)\n","\n","                section_results = {\n","                    'marks': 0,\n","                    'total_questions': 0,\n","                    'correct': 0,\n","                    'wrong': 0,\n","                    'unattempted': 0,\n","                    'multiple_marked': 0,\n","                    'questions': {}\n","                }\n","\n","                solution_section = solution_json.get(section_name, {})\n","\n","                # Store question range for this section\n","                question_nums = [int(q) for q in section_data.keys()]\n","                section_question_ranges[section_name] = {\n","                    'min': min(question_nums),\n","                    'max': max(question_nums),\n","                    'nums': sorted(question_nums)\n","                }\n","\n","                for question_num, student_answer in section_data.items():\n","                    correct_answer = solution_section.get(question_num)\n","\n","                    question_key = f\"{section_name.replace('_', ' ').title()}  Q-{question_num}\"\n","                    question_result = {\n","                        'student_answer': student_answer,\n","                        'correct_answer': correct_answer,\n","                        'marks': 0,\n","                        'status': 'unattempted'\n","                    }\n","\n","                    section_results['total_questions'] += 1\n","\n","                    if student_answer == 'X':\n","                        question_result['marks'] = if_wrong\n","                        question_result['status'] = 'multiple_marked'\n","                        section_results['multiple_marked'] += 1\n","                        section_results['marks'] += if_wrong\n","\n","                    elif student_answer is None:\n","                        question_result['marks'] = 0\n","                        question_result['status'] = 'unattempted'\n","                        section_results['unattempted'] += 1\n","\n","                    elif student_answer == correct_answer:\n","                        question_result['marks'] = if_correct\n","                        question_result['status'] = 'correct'\n","                        section_results['correct'] += 1\n","                        section_results['marks'] += if_correct\n","\n","                    else:\n","                        question_result['marks'] = if_wrong\n","                        question_result['status'] = 'wrong'\n","                        section_results['wrong'] += 1\n","                        section_results['marks'] += if_wrong\n","\n","                    section_results['questions'][question_key] = question_result\n","                    results['question_wise_analysis'][question_key] = question_result\n","\n","                results['section_wise_marks'][section_name] = section_results\n","\n","            else:\n","                results['custom_fields'][section_name] = section_data\n","\n","    # Safe section combination with dynamic updates\n","    changed = True\n","    while changed:\n","        changed = False\n","        section_names = list(results['section_wise_marks'].keys())\n","\n","        for i in range(len(section_names) - 1):\n","            current_section = section_names[i]\n","            next_section = section_names[i + 1]\n","\n","            # Check if both sections exist and can be combined\n","            if (current_section in results['section_wise_marks'] and\n","                next_section in results['section_wise_marks'] and\n","                can_combine_sections(current_section, next_section, section_question_ranges)):\n","\n","                # Combine next section into current section\n","                current_data = results['section_wise_marks'][current_section]\n","                next_data = results['section_wise_marks'][next_section]\n","\n","                # Merge all data\n","                current_data['marks'] += next_data['marks']\n","                current_data['total_questions'] += next_data['total_questions']\n","                current_data['correct'] += next_data['correct']\n","                current_data['wrong'] += next_data['wrong']\n","                current_data['unattempted'] += next_data['unattempted']\n","                current_data['multiple_marked'] += next_data['multiple_marked']\n","                current_data['questions'].update(next_data['questions'])\n","\n","                # Remove the merged section\n","                del results['section_wise_marks'][next_section]\n","\n","                # Mark that we made a change and break to restart\n","                changed = True\n","                break\n","\n","    # Calculate totals\n","    for section_data in results['section_wise_marks'].values():\n","        results['total_marks'] += section_data['marks']\n","        results['total_questions'] += section_data['total_questions']\n","        results['correct_answers'] += section_data['correct']\n","        results['wrong_answers'] += section_data['wrong']\n","        results['unattempted'] += section_data['unattempted']\n","        results['multiple_marked'] += section_data['multiple_marked']\n","\n","    # Calculate summary statistics\n","    total_q = results['total_questions']\n","    if total_q > 0:\n","        results['summary'] = {\n","            'accuracy_percentage': round((results['correct_answers'] / total_q) * 100, 2),\n","            'attempted_percentage': round(((total_q - results['unattempted']) / total_q) * 100, 2),\n","            'maximum_possible_marks': total_q * if_correct,\n","            'minimum_possible_marks': total_q * if_wrong,\n","            'marks_percentage': round((results['total_marks'] / (total_q * if_correct)) * 100, 2) if total_q * if_correct > 0 else 0\n","        }\n","\n","    return get_results_markdown(results)\n","\n","\n","def can_combine_sections(current_section, next_section, section_question_ranges):\n","    current_range = section_question_ranges[current_section]\n","    next_range = section_question_ranges[next_section]\n","\n","    is_continuous = (current_range['max'] + 1 == next_range['min'])  # 30 + 1 == 31 ‚úì\n","\n","    base_current = re.sub(r'[_\\-]?(part|section)?\\d*$', '', current_section.lower())\n","    base_next = re.sub(r'[_\\-]?(part|section)?\\d*$', '', next_section.lower())\n","\n","    base_current = base_current.rstrip('_-')\n","    base_next = base_next.rstrip('_-')\n","\n","    return is_continuous and (base_current == base_next)\n","\n","def get_results_markdown(results):\n","    md_lines = []\n","\n","    # Header\n","    md_lines.append(\"# OMR ANSWER SHEET GRADING RESULTS\")\n","    md_lines.append(\"=\" * 80)\n","    md_lines.append(\"\")\n","\n","    # Student Information\n","    if results['student_info']:\n","        md_lines.append(\"## üìã Student Information\")\n","        md_lines.append(\"\")\n","        for key, value in results['student_info'].items():\n","            md_lines.append(f\"- **{key.replace('_', ' ').title()}:** {value}\")\n","        md_lines.append(\"\")\n","\n","    # Custom Fields\n","    if results['custom_fields']:\n","        md_lines.append(\"## üìù Custom Fields\")\n","        md_lines.append(\"\")\n","        for key, value in results['custom_fields'].items():\n","            if isinstance(value, dict):\n","                md_lines.append(f\"- **{key.replace('_', ' ').title()}:**\")\n","                for sub_key, sub_value in value.items():\n","                    clean_key = sub_key.replace('field_', '').replace('_', ' ').title()\n","                    md_lines.append(f\"  - {clean_key}: {sub_value}\")\n","            else:\n","                md_lines.append(f\"- **{key.replace('_', ' ').title()}:** {value}\")\n","        md_lines.append(\"\")\n","\n","    # Overall Performance\n","    md_lines.append(\"## üéØ Overall Performance\")\n","    md_lines.append(\"\")\n","    md_lines.append(f\"- **Total Questions:** {results['total_questions']}\")\n","    md_lines.append(f\"- **Total Marks:** {results['total_marks']}\")\n","    md_lines.append(f\"- **Correct Answers:** {results['correct_answers']}\")\n","    md_lines.append(f\"- **Wrong Answers:** {results['wrong_answers']}\")\n","    md_lines.append(f\"- **Unattempted:** {results['unattempted']}\")\n","    md_lines.append(f\"- **Multiple Marked:** {results['multiple_marked']}\")\n","    md_lines.append(\"\")\n","\n","    # Statistics\n","    if results['summary']:\n","        summary = results['summary']\n","        md_lines.append(\"### üìä Statistics\")\n","        md_lines.append(\"\")\n","        md_lines.append(f\"- **Accuracy:** {summary['accuracy_percentage']}%\")\n","        md_lines.append(f\"- **Attempted:** {summary['attempted_percentage']}%\")\n","        md_lines.append(f\"- **Score:** {summary['marks_percentage']}%\")\n","        md_lines.append(f\"- **Max Possible:** {summary['maximum_possible_marks']}\")\n","        md_lines.append(f\"- **Min Possible:** {summary['minimum_possible_marks']}\")\n","        md_lines.append(\"\")\n","\n","    # Section-wise Breakdown\n","    md_lines.append(\"## üìö Section-wise Breakdown\")\n","    md_lines.append(\"\")\n","    for section_name, section_data in results['section_wise_marks'].items():\n","        md_lines.append(f\"### üîπ {section_name.replace('_', ' ').title()}\")\n","        md_lines.append(\"\")\n","        md_lines.append(f\"- **Questions:** {section_data['total_questions']}\")\n","        md_lines.append(f\"- **Marks:** {section_data['marks']}\")\n","        md_lines.append(f\"- **‚úì Correct:** {section_data['correct']}\")\n","        md_lines.append(f\"- **‚úó Wrong:** {section_data['wrong']}\")\n","        md_lines.append(f\"- **‚óã Unattempted:** {section_data['unattempted']}\")\n","        md_lines.append(f\"- **‚ö† Multiple:** {section_data['multiple_marked']}\")\n","        md_lines.append(\"\")\n","\n","    # Question-wise Analysis\n","    md_lines.append(\"## üîç Question-wise Analysis\")\n","    md_lines.append(\"\")\n","\n","    for q_key, q_data in results['question_wise_analysis'].items():\n","        status_icon = {\n","            'correct': '‚úì',\n","            'wrong': '‚úó',\n","            'unattempted': '‚óã',\n","            'multiple_marked': '‚ö†'\n","        }.get(q_data['status'], '?')\n","\n","        md_lines.append(f\"- {status_icon} **{q_key}:** {q_data['student_answer']} \"\n","                       f\"(Correct: {q_data['correct_answer']}) = **{q_data['marks']} marks**\")\n","\n","    return \"\\n\".join(md_lines)\n","\n","\n","def convert_solutions_json(decoded_data, solutions_path):\n","    with open(solutions_path, 'r') as f:\n","        data = json.load(f)\n","\n","    # Create a deep copy to avoid modifying the original\n","    decoded_copy = copy.deepcopy(decoded_data)\n","\n","    option_map = {'a': 'A', 'b': 'B', 'c': 'C', 'd': 'D'}\n","    solution_answers = [\n","        option_map.get(ans.get(\"correctOption\", \"\").lower(), ans.get(\"correctOption\", \"\").upper())\n","        for ans in data.get(\"answers\", [])\n","    ]\n","\n","    # Flatten decoded_data question keys in section & question number order\n","    question_locations = []\n","    for section in decoded_copy:\n","        if isinstance(decoded_copy[section], dict):\n","            for qno in sorted(decoded_copy[section], key=lambda x: int(x)):\n","                question_locations.append((section, qno))\n","\n","    for i, (section, qno) in enumerate(question_locations):\n","        if i < len(solution_answers):\n","            decoded_copy[section][qno] = solution_answers[i]\n","        else:\n","            break\n","\n","    return decoded_copy\n","\n","\n","\n","\n","\n","def check_answers(input_omr, solutions_json, omr_template,\n","                                    if_correct=4, if_wrong=-1,\n","                                    thresh_size=201, aspect_ratio_tolerance=1,\n","                                    check_orientation=True):\n","\n","\n","\n","    answer_sheet, answers = decode_omr(input_omr, omr_template,\n","                                       thresh_size, aspect_ratio_tolerance,\n","                                       check_orientation)\n","\n","    solutions = convert_solutions_json(answers,solutions_json)\n","\n","\n","    if answer_sheet is None or answers is None:\n","        return \"Please ensure the uploaded image is clear and the markers are clearly visible\"\n","\n","    # Grade the decoded answers against solutions\n","    results_markdown = grade_omr_sheet(solutions, answers, if_correct, if_wrong)\n","    return results_markdown\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2070,"status":"ok","timestamp":1750236486745,"user":{"displayName":"Taanush abraham","userId":"16497560746847074205"},"user_tz":-330},"id":"IeCqeCmTvhbi","outputId":"49dcf77d-3144-40e5-aa42-aa81fac449b1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Contour 1: Valid marker candidate found with SAD score 0!\n","Contour 1: Extracted Pattern:\n","[[0 1 0]\n"," [1 0 1]\n"," [0 1 0]]\n","Contour 1: SAD Score = 0. Max tolerance = 4\n","Contour 2: Valid marker candidate found with SAD score 0!\n","Contour 2: Extracted Pattern:\n","[[0 1 0]\n"," [1 0 1]\n"," [0 1 0]]\n","Contour 2: SAD Score = 0. Max tolerance = 4\n","Contour 106: Valid marker candidate found with SAD score 0!\n","Contour 106: Extracted Pattern:\n","[[0 1 0]\n"," [1 0 1]\n"," [0 1 0]]\n","Contour 106: SAD Score = 0. Max tolerance = 4\n","Contour 107: Valid marker candidate found with SAD score 0!\n","Contour 107: Extracted Pattern:\n","[[0 1 0]\n"," [1 0 1]\n"," [0 1 0]]\n","Contour 107: SAD Score = 0. Max tolerance = 4\n","‚úÖ Template loaded: 9 regions found\n","Found 820 potential bubbles after dynamic filtering.\n","roll_no\n","__\n","physics_-_1\n","{'1': 'B', '2': 'A', '3': 'D', '4': 'D', '5': 'A', '6': 'C', '7': 'A', '8': 'C', '9': 'D', '10': 'D', '11': 'A', '12': 'B', '13': 'B', '14': 'C', '15': 'D', '16': 'D', '17': 'D', '18': 'C', '19': 'B', '20': 'C', '21': 'A', '22': 'B', '23': 'D', '24': 'C', '25': 'D', '26': 'B', '27': 'B', '28': 'C', '29': 'A', '30': 'D', '31': 'C', '32': 'A', '33': 'D', '34': 'D', '35': 'D'}\n","physics_-_2\n","{'36': None, '37': 'D', '38': 'D', '39': 'A', '40': None, '41': 'A', '42': 'A', '43': 'B', '44': 'D', '45': 'A', '46': 'D', '47': None, '48': 'C', '49': None, '50': None}\n","chemistry_-_1\n","{'1': 'B', '2': 'C', '3': 'B', '4': 'C', '5': 'B', '6': 'C', '7': 'B', '8': 'D', '9': 'B', '10': 'C', '11': 'D', '12': 'C', '13': 'B', '14': 'A', '15': 'C', '16': 'A', '17': 'B', '18': 'B', '19': 'D', '20': 'A', '21': 'A', '22': 'D', '23': 'C', '24': 'C', '25': 'A', '26': 'B', '27': 'B', '28': 'A', '29': 'A'}\n","chemistry_-_2\n","{'30': 'A', '31': 'D', '32': 'A', '33': 'B', '34': 'D', '35': 'C', '36': 'A', '37': 'B', '38': 'D', '39': 'D', '40': 'A', '41': 'A', '42': 'C', '43': 'B', '44': 'A', '45': 'D', '46': None, '47': None, '48': None, '49': None, '50': None}\n","botany_-_1\n","{'1': 'D', '2': 'A', '3': 'D', '4': 'C', '5': 'B', '6': 'A', '7': 'B', '8': 'A', '9': 'D', '10': 'A', '11': 'A', '12': 'C', '13': 'A', '14': 'A', '15': 'A', '16': 'B', '17': 'A', '18': 'C', '19': 'D', '20': 'C', '21': 'C', '22': 'D', '23': 'B'}\n","botany_-_2\n","{'24': 'C', '25': 'A', '26': 'C', '27': 'D', '28': 'C', '29': 'D', '30': 'D', '31': 'B', '32': 'C', '33': 'A', '34': 'A', '35': 'D', '36': None, '37': 'B', '38': 'B', '39': 'C', '40': 'D', '41': 'C', '42': 'A', '43': 'C', '44': 'A', '45': 'C', '46': 'A', '47': None, '48': None, '49': None, '50': None}\n","zoology_-_1\n","{'1': 'D', '2': 'A', '3': 'D', '4': 'B', '5': 'D', '6': 'D', '7': 'D', '8': 'A', '9': 'A', '10': 'C', '11': 'B', '12': 'A', '13': 'C', '14': 'C', '15': 'A', '16': 'D', '17': 'B', '18': 'A'}\n","zoology_-_2\n","{'19': 'B', '20': 'D', '21': 'C', '22': 'C', '23': 'D', '24': 'D', '25': 'A', '26': 'C', '27': 'B', '28': 'D', '29': 'C', '30': 'A', '31': 'A', '32': 'D', '33': 'B', '34': 'C', '35': 'D', '36': 'A', '37': 'B', '38': 'A', '39': 'C', '40': 'A', '41': 'C', '42': None, '43': 'A', '44': 'A', '45': 'D', '46': 'A', '47': None, '48': None, '49': None, '50': None}\n","roll_no\n","__\n","physics_-_1\n","{'1': 'D', '2': 'B', '3': 'A', '4': 'C', '5': 'B', '6': 'A', '7': 'D', '8': 'C', '9': 'B', '10': 'C', '11': 'B', '12': 'C', '13': 'B', '14': 'C', '15': 'D', '16': 'A', '17': 'B', '18': 'C', '19': 'B', '20': 'C', '21': 'A,B', '22': 'D', '23': 'B', '24': 'B', '25': 'D', '26': 'B', '27': 'A', '28': 'B', '29': 'B', '30': 'C', '31': 'B', '32': 'B', '33': 'A', '34': 'A', '35': 'B'}\n","physics_-_2\n","{'36': 'A', '37': 'A', '38': 'C', '39': 'B', '40': 'B', '41': 'C', '42': 'A', '43': 'A', '44': 'A', '45': 'C', '46': 'C', '47': 'C', '48': 'C', '49': 'B', '50': 'A'}\n","chemistry_-_1\n","{'1': 'D', '2': 'C', '3': 'A', '4': 'D', '5': 'C', '6': 'B', '7': 'D', '8': 'A', '9': 'A', '10': 'B', '11': 'B', '12': 'A', '13': 'B', '14': 'C', '15': 'A', '16': 'D', '17': 'C', '18': 'C', '19': 'A', '20': 'D', '21': 'D', '22': 'A', '23': 'B', '24': 'C', '25': 'D', '26': 'B', '27': 'D', '28': 'A', '29': 'A,B,C'}\n","chemistry_-_2\n","{'30': 'C', '31': 'B', '32': 'B', '33': 'A', '34': 'B', '35': 'B', '36': 'B', '37': 'A', '38': 'B', '39': 'A', '40': 'B', '41': 'C', '42': 'D', '43': 'C', '44': 'C', '45': 'A', '46': 'A', '47': 'D', '48': 'D', '49': 'C', '50': 'C'}\n","botany_-_1\n","{'1': 'A', '2': 'A', '3': 'B', '4': 'A', '5': 'B', '6': 'A', '7': 'B', '8': 'C', '9': 'B', '10': 'C', '11': 'C', '12': 'B', '13': 'C', '14': 'B', '15': 'B', '16': 'B', '17': 'A', '18': 'C', '19': 'D', '20': 'C', '21': 'C', '22': 'D', '23': 'B'}\n","botany_-_2\n","{'24': 'C', '25': 'A', '26': 'C', '27': 'D', '28': 'C', '29': 'D', '30': 'D', '31': 'B', '32': 'C', '33': 'A', '34': 'A', '35': 'D', '36': None, '37': 'B', '38': 'B', '39': 'C', '40': 'D', '41': 'C', '42': 'A', '43': 'C', '44': 'A', '45': 'C', '46': 'A', '47': None, '48': None, '49': None, '50': None}\n","zoology_-_1\n","{'1': 'D', '2': 'A', '3': 'D', '4': 'B', '5': 'D', '6': 'D', '7': 'D', '8': 'A', '9': 'A', '10': 'C', '11': 'B', '12': 'A', '13': 'C', '14': 'C', '15': 'A', '16': 'D', '17': 'B', '18': 'A'}\n","zoology_-_2\n","{'19': 'B', '20': 'D', '21': 'C', '22': 'C', '23': 'D', '24': 'D', '25': 'A', '26': 'C', '27': 'B', '28': 'D', '29': 'C', '30': 'A', '31': 'A', '32': 'D', '33': 'B', '34': 'C', '35': 'D', '36': 'A', '37': 'B', '38': 'A', '39': 'C', '40': 'A', '41': 'C', '42': None, '43': 'A', '44': 'A', '45': 'D', '46': 'A', '47': None, '48': None, '49': None, '50': None}\n","roll_no\n","__\n","physics_-_1\n","{'1': 'B', '2': 'A', '3': 'D', '4': 'D', '5': 'A', '6': 'C', '7': 'A', '8': 'C', '9': 'D', '10': 'D', '11': 'A', '12': 'B', '13': 'B', '14': 'C', '15': 'D', '16': 'D', '17': 'D', '18': 'C', '19': 'B', '20': 'C', '21': 'A', '22': 'B', '23': 'D', '24': 'C', '25': 'D', '26': 'B', '27': 'B', '28': 'C', '29': 'A', '30': 'D', '31': 'C', '32': 'A', '33': 'D', '34': 'D', '35': 'D'}\n","physics_-_2\n","{'36': None, '37': 'D', '38': 'D', '39': 'A', '40': None, '41': 'A', '42': 'A', '43': 'B', '44': 'D', '45': 'A', '46': 'D', '47': None, '48': 'C', '49': None, '50': None}\n","chemistry_-_1\n","{'1': 'B', '2': 'C', '3': 'B', '4': 'C', '5': 'B', '6': 'C', '7': 'B', '8': 'D', '9': 'B', '10': 'C', '11': 'D', '12': 'C', '13': 'B', '14': 'A', '15': 'C', '16': 'A', '17': 'B', '18': 'B', '19': 'D', '20': 'A', '21': 'A', '22': 'D', '23': 'C', '24': 'C', '25': 'A', '26': 'B', '27': 'B', '28': 'A', '29': 'A'}\n","chemistry_-_2\n","{'30': 'A', '31': 'D', '32': 'A', '33': 'B', '34': 'D', '35': 'C', '36': 'A', '37': 'B', '38': 'D', '39': 'D', '40': 'A', '41': 'A', '42': 'C', '43': 'B', '44': 'A', '45': 'D', '46': None, '47': None, '48': None, '49': None, '50': None}\n","botany_-_1\n","{'1': 'D', '2': 'A', '3': 'D', '4': 'C', '5': 'B', '6': 'A', '7': 'B', '8': 'A', '9': 'D', '10': 'A', '11': 'A', '12': 'C', '13': 'A', '14': 'A', '15': 'A', '16': 'B', '17': 'A', '18': 'C', '19': 'D', '20': 'C', '21': 'C', '22': 'D', '23': 'B'}\n","botany_-_2\n","{'24': 'C', '25': 'A', '26': 'C', '27': 'D', '28': 'C', '29': 'D', '30': 'D', '31': 'B', '32': 'C', '33': 'A', '34': 'A', '35': 'D', '36': None, '37': 'B', '38': 'B', '39': 'C', '40': 'D', '41': 'C', '42': 'A', '43': 'C', '44': 'A', '45': 'C', '46': 'A', '47': None, '48': None, '49': None, '50': None}\n","zoology_-_1\n","{'1': 'D', '2': 'A', '3': 'D', '4': 'B', '5': 'D', '6': 'D', '7': 'D', '8': 'A', '9': 'A', '10': 'C', '11': 'B', '12': 'A', '13': 'C', '14': 'C', '15': 'A', '16': 'D', '17': 'B', '18': 'A'}\n","zoology_-_2\n","{'19': 'B', '20': 'D', '21': 'C', '22': 'C', '23': 'D', '24': 'D', '25': 'A', '26': 'C', '27': 'B', '28': 'D', '29': 'C', '30': 'A', '31': 'A', '32': 'D', '33': 'B', '34': 'C', '35': 'D', '36': 'A', '37': 'B', '38': 'A', '39': 'C', '40': 'A', '41': 'C', '42': None, '43': 'A', '44': 'A', '45': 'D', '46': 'A', '47': None, '48': None, '49': None, '50': None}\n","# OMR ANSWER SHEET GRADING RESULTS\n","================================================================================\n","\n","## üìã Student Information\n","\n","- **Roll No:** __\n","\n","## üéØ Overall Performance\n","\n","- **Total Questions:** 200\n","- **Total Marks:** 295\n","- **Correct Answers:** 95\n","- **Wrong Answers:** 85\n","- **Unattempted:** 20\n","- **Multiple Marked:** 0\n","\n","### üìä Statistics\n","\n","- **Accuracy:** 47.5%\n","- **Attempted:** 90.0%\n","- **Score:** 36.88%\n","- **Max Possible:** 800\n","- **Min Possible:** -200\n","\n","## üìö Section-wise Breakdown\n","\n","### üîπ Physics - 1\n","\n","- **Questions:** 50\n","- **Marks:** 10\n","- **‚úì Correct:** 11\n","- **‚úó Wrong:** 34\n","- **‚óã Unattempted:** 5\n","- **‚ö† Multiple:** 0\n","\n","### üîπ Chemistry - 1\n","\n","- **Questions:** 50\n","- **Marks:** -20\n","- **‚úì Correct:** 5\n","- **‚úó Wrong:** 40\n","- **‚óã Unattempted:** 5\n","- **‚ö† Multiple:** 0\n","\n","### üîπ Botany - 1\n","\n","- **Questions:** 50\n","- **Marks:** 125\n","- **‚úì Correct:** 34\n","- **‚úó Wrong:** 11\n","- **‚óã Unattempted:** 5\n","- **‚ö† Multiple:** 0\n","\n","### üîπ Zoology - 1\n","\n","- **Questions:** 50\n","- **Marks:** 180\n","- **‚úì Correct:** 45\n","- **‚úó Wrong:** 0\n","- **‚óã Unattempted:** 5\n","- **‚ö† Multiple:** 0\n","\n","## üîç Question-wise Analysis\n","\n","- ‚úó **Physics - 1  Q-1:** B (Correct: D) = **-1 marks**\n","- ‚úó **Physics - 1  Q-2:** A (Correct: B) = **-1 marks**\n","- ‚úó **Physics - 1  Q-3:** D (Correct: A) = **-1 marks**\n","- ‚úó **Physics - 1  Q-4:** D (Correct: C) = **-1 marks**\n","- ‚úó **Physics - 1  Q-5:** A (Correct: B) = **-1 marks**\n","- ‚úó **Physics - 1  Q-6:** C (Correct: A) = **-1 marks**\n","- ‚úó **Physics - 1  Q-7:** A (Correct: D) = **-1 marks**\n","- ‚úì **Physics - 1  Q-8:** C (Correct: C) = **4 marks**\n","- ‚úó **Physics - 1  Q-9:** D (Correct: B) = **-1 marks**\n","- ‚úó **Physics - 1  Q-10:** D (Correct: C) = **-1 marks**\n","- ‚úó **Physics - 1  Q-11:** A (Correct: B) = **-1 marks**\n","- ‚úó **Physics - 1  Q-12:** B (Correct: C) = **-1 marks**\n","- ‚úì **Physics - 1  Q-13:** B (Correct: B) = **4 marks**\n","- ‚úì **Physics - 1  Q-14:** C (Correct: C) = **4 marks**\n","- ‚úì **Physics - 1  Q-15:** D (Correct: D) = **4 marks**\n","- ‚úó **Physics - 1  Q-16:** D (Correct: A) = **-1 marks**\n","- ‚úó **Physics - 1  Q-17:** D (Correct: B) = **-1 marks**\n","- ‚úì **Physics - 1  Q-18:** C (Correct: C) = **4 marks**\n","- ‚úì **Physics - 1  Q-19:** B (Correct: B) = **4 marks**\n","- ‚úì **Physics - 1  Q-20:** C (Correct: C) = **4 marks**\n","- ‚úó **Physics - 1  Q-21:** A (Correct: A,B) = **-1 marks**\n","- ‚úó **Physics - 1  Q-22:** B (Correct: D) = **-1 marks**\n","- ‚úó **Physics - 1  Q-23:** D (Correct: B) = **-1 marks**\n","- ‚úó **Physics - 1  Q-24:** C (Correct: B) = **-1 marks**\n","- ‚úì **Physics - 1  Q-25:** D (Correct: D) = **4 marks**\n","- ‚úì **Physics - 1  Q-26:** B (Correct: B) = **4 marks**\n","- ‚úó **Physics - 1  Q-27:** B (Correct: A) = **-1 marks**\n","- ‚úó **Physics - 1  Q-28:** C (Correct: B) = **-1 marks**\n","- ‚úó **Physics - 1  Q-29:** A (Correct: B) = **-1 marks**\n","- ‚úó **Physics - 1  Q-30:** D (Correct: C) = **-1 marks**\n","- ‚úó **Physics - 1  Q-31:** C (Correct: B) = **-1 marks**\n","- ‚úó **Physics - 1  Q-32:** A (Correct: B) = **-1 marks**\n","- ‚úó **Physics - 1  Q-33:** D (Correct: A) = **-1 marks**\n","- ‚úó **Physics - 1  Q-34:** D (Correct: A) = **-1 marks**\n","- ‚úó **Physics - 1  Q-35:** D (Correct: B) = **-1 marks**\n","- ‚óã **Physics - 2  Q-36:** None (Correct: A) = **0 marks**\n","- ‚úó **Physics - 2  Q-37:** D (Correct: A) = **-1 marks**\n","- ‚úó **Physics - 2  Q-38:** D (Correct: C) = **-1 marks**\n","- ‚úó **Physics - 2  Q-39:** A (Correct: B) = **-1 marks**\n","- ‚óã **Physics - 2  Q-40:** None (Correct: B) = **0 marks**\n","- ‚úó **Physics - 2  Q-41:** A (Correct: C) = **-1 marks**\n","- ‚úì **Physics - 2  Q-42:** A (Correct: A) = **4 marks**\n","- ‚úó **Physics - 2  Q-43:** B (Correct: A) = **-1 marks**\n","- ‚úó **Physics - 2  Q-44:** D (Correct: A) = **-1 marks**\n","- ‚úó **Physics - 2  Q-45:** A (Correct: C) = **-1 marks**\n","- ‚úó **Physics - 2  Q-46:** D (Correct: C) = **-1 marks**\n","- ‚óã **Physics - 2  Q-47:** None (Correct: C) = **0 marks**\n","- ‚úì **Physics - 2  Q-48:** C (Correct: C) = **4 marks**\n","- ‚óã **Physics - 2  Q-49:** None (Correct: B) = **0 marks**\n","- ‚óã **Physics - 2  Q-50:** None (Correct: A) = **0 marks**\n","- ‚úó **Chemistry - 1  Q-1:** B (Correct: D) = **-1 marks**\n","- ‚úì **Chemistry - 1  Q-2:** C (Correct: C) = **4 marks**\n","- ‚úó **Chemistry - 1  Q-3:** B (Correct: A) = **-1 marks**\n","- ‚úó **Chemistry - 1  Q-4:** C (Correct: D) = **-1 marks**\n","- ‚úó **Chemistry - 1  Q-5:** B (Correct: C) = **-1 marks**\n","- ‚úó **Chemistry - 1  Q-6:** C (Correct: B) = **-1 marks**\n","- ‚úó **Chemistry - 1  Q-7:** B (Correct: D) = **-1 marks**\n","- ‚úó **Chemistry - 1  Q-8:** D (Correct: A) = **-1 marks**\n","- ‚úó **Chemistry - 1  Q-9:** B (Correct: A) = **-1 marks**\n","- ‚úó **Chemistry - 1  Q-10:** C (Correct: B) = **-1 marks**\n","- ‚úó **Chemistry - 1  Q-11:** D (Correct: B) = **-1 marks**\n","- ‚úó **Chemistry - 1  Q-12:** C (Correct: A) = **-1 marks**\n","- ‚úì **Chemistry - 1  Q-13:** B (Correct: B) = **4 marks**\n","- ‚úó **Chemistry - 1  Q-14:** A (Correct: C) = **-1 marks**\n","- ‚úó **Chemistry - 1  Q-15:** C (Correct: A) = **-1 marks**\n","- ‚úó **Chemistry - 1  Q-16:** A (Correct: D) = **-1 marks**\n","- ‚úó **Chemistry - 1  Q-17:** B (Correct: C) = **-1 marks**\n","- ‚úó **Chemistry - 1  Q-18:** B (Correct: C) = **-1 marks**\n","- ‚úó **Chemistry - 1  Q-19:** D (Correct: A) = **-1 marks**\n","- ‚úó **Chemistry - 1  Q-20:** A (Correct: D) = **-1 marks**\n","- ‚úó **Chemistry - 1  Q-21:** A (Correct: D) = **-1 marks**\n","- ‚úó **Chemistry - 1  Q-22:** D (Correct: A) = **-1 marks**\n","- ‚úó **Chemistry - 1  Q-23:** C (Correct: B) = **-1 marks**\n","- ‚úì **Chemistry - 1  Q-24:** C (Correct: C) = **4 marks**\n","- ‚úó **Chemistry - 1  Q-25:** A (Correct: D) = **-1 marks**\n","- ‚úì **Chemistry - 1  Q-26:** B (Correct: B) = **4 marks**\n","- ‚úó **Chemistry - 1  Q-27:** B (Correct: D) = **-1 marks**\n","- ‚úì **Chemistry - 1  Q-28:** A (Correct: A) = **4 marks**\n","- ‚úó **Chemistry - 1  Q-29:** A (Correct: A,B,C) = **-1 marks**\n","- ‚úó **Chemistry - 2  Q-30:** A (Correct: C) = **-1 marks**\n","- ‚úó **Chemistry - 2  Q-31:** D (Correct: B) = **-1 marks**\n","- ‚úó **Chemistry - 2  Q-32:** A (Correct: B) = **-1 marks**\n","- ‚úó **Chemistry - 2  Q-33:** B (Correct: A) = **-1 marks**\n","- ‚úó **Chemistry - 2  Q-34:** D (Correct: B) = **-1 marks**\n","- ‚úó **Chemistry - 2  Q-35:** C (Correct: B) = **-1 marks**\n","- ‚úó **Chemistry - 2  Q-36:** A (Correct: B) = **-1 marks**\n","- ‚úó **Chemistry - 2  Q-37:** B (Correct: A) = **-1 marks**\n","- ‚úó **Chemistry - 2  Q-38:** D (Correct: B) = **-1 marks**\n","- ‚úó **Chemistry - 2  Q-39:** D (Correct: A) = **-1 marks**\n","- ‚úó **Chemistry - 2  Q-40:** A (Correct: B) = **-1 marks**\n","- ‚úó **Chemistry - 2  Q-41:** A (Correct: C) = **-1 marks**\n","- ‚úó **Chemistry - 2  Q-42:** C (Correct: D) = **-1 marks**\n","- ‚úó **Chemistry - 2  Q-43:** B (Correct: C) = **-1 marks**\n","- ‚úó **Chemistry - 2  Q-44:** A (Correct: C) = **-1 marks**\n","- ‚úó **Chemistry - 2  Q-45:** D (Correct: A) = **-1 marks**\n","- ‚óã **Chemistry - 2  Q-46:** None (Correct: A) = **0 marks**\n","- ‚óã **Chemistry - 2  Q-47:** None (Correct: D) = **0 marks**\n","- ‚óã **Chemistry - 2  Q-48:** None (Correct: D) = **0 marks**\n","- ‚óã **Chemistry - 2  Q-49:** None (Correct: C) = **0 marks**\n","- ‚óã **Chemistry - 2  Q-50:** None (Correct: C) = **0 marks**\n","- ‚úó **Botany - 1  Q-1:** D (Correct: A) = **-1 marks**\n","- ‚úì **Botany - 1  Q-2:** A (Correct: A) = **4 marks**\n","- ‚úó **Botany - 1  Q-3:** D (Correct: B) = **-1 marks**\n","- ‚úó **Botany - 1  Q-4:** C (Correct: A) = **-1 marks**\n","- ‚úì **Botany - 1  Q-5:** B (Correct: B) = **4 marks**\n","- ‚úì **Botany - 1  Q-6:** A (Correct: A) = **4 marks**\n","- ‚úì **Botany - 1  Q-7:** B (Correct: B) = **4 marks**\n","- ‚úó **Botany - 1  Q-8:** A (Correct: C) = **-1 marks**\n","- ‚úó **Botany - 1  Q-9:** D (Correct: B) = **-1 marks**\n","- ‚úó **Botany - 1  Q-10:** A (Correct: C) = **-1 marks**\n","- ‚úó **Botany - 1  Q-11:** A (Correct: C) = **-1 marks**\n","- ‚úó **Botany - 1  Q-12:** C (Correct: B) = **-1 marks**\n","- ‚úó **Botany - 1  Q-13:** A (Correct: C) = **-1 marks**\n","- ‚úó **Botany - 1  Q-14:** A (Correct: B) = **-1 marks**\n","- ‚úó **Botany - 1  Q-15:** A (Correct: B) = **-1 marks**\n","- ‚úì **Botany - 1  Q-16:** B (Correct: B) = **4 marks**\n","- ‚úì **Botany - 1  Q-17:** A (Correct: A) = **4 marks**\n","- ‚úì **Botany - 1  Q-18:** C (Correct: C) = **4 marks**\n","- ‚úì **Botany - 1  Q-19:** D (Correct: D) = **4 marks**\n","- ‚úì **Botany - 1  Q-20:** C (Correct: C) = **4 marks**\n","- ‚úì **Botany - 1  Q-21:** C (Correct: C) = **4 marks**\n","- ‚úì **Botany - 1  Q-22:** D (Correct: D) = **4 marks**\n","- ‚úì **Botany - 1  Q-23:** B (Correct: B) = **4 marks**\n","- ‚úì **Botany - 2  Q-24:** C (Correct: C) = **4 marks**\n","- ‚úì **Botany - 2  Q-25:** A (Correct: A) = **4 marks**\n","- ‚úì **Botany - 2  Q-26:** C (Correct: C) = **4 marks**\n","- ‚úì **Botany - 2  Q-27:** D (Correct: D) = **4 marks**\n","- ‚úì **Botany - 2  Q-28:** C (Correct: C) = **4 marks**\n","- ‚úì **Botany - 2  Q-29:** D (Correct: D) = **4 marks**\n","- ‚úì **Botany - 2  Q-30:** D (Correct: D) = **4 marks**\n","- ‚úì **Botany - 2  Q-31:** B (Correct: B) = **4 marks**\n","- ‚úì **Botany - 2  Q-32:** C (Correct: C) = **4 marks**\n","- ‚úì **Botany - 2  Q-33:** A (Correct: A) = **4 marks**\n","- ‚úì **Botany - 2  Q-34:** A (Correct: A) = **4 marks**\n","- ‚úì **Botany - 2  Q-35:** D (Correct: D) = **4 marks**\n","- ‚óã **Botany - 2  Q-36:** None (Correct: None) = **0 marks**\n","- ‚úì **Botany - 2  Q-37:** B (Correct: B) = **4 marks**\n","- ‚úì **Botany - 2  Q-38:** B (Correct: B) = **4 marks**\n","- ‚úì **Botany - 2  Q-39:** C (Correct: C) = **4 marks**\n","- ‚úì **Botany - 2  Q-40:** D (Correct: D) = **4 marks**\n","- ‚úì **Botany - 2  Q-41:** C (Correct: C) = **4 marks**\n","- ‚úì **Botany - 2  Q-42:** A (Correct: A) = **4 marks**\n","- ‚úì **Botany - 2  Q-43:** C (Correct: C) = **4 marks**\n","- ‚úì **Botany - 2  Q-44:** A (Correct: A) = **4 marks**\n","- ‚úì **Botany - 2  Q-45:** C (Correct: C) = **4 marks**\n","- ‚úì **Botany - 2  Q-46:** A (Correct: A) = **4 marks**\n","- ‚óã **Botany - 2  Q-47:** None (Correct: None) = **0 marks**\n","- ‚óã **Botany - 2  Q-48:** None (Correct: None) = **0 marks**\n","- ‚óã **Botany - 2  Q-49:** None (Correct: None) = **0 marks**\n","- ‚óã **Botany - 2  Q-50:** None (Correct: None) = **0 marks**\n","- ‚úì **Zoology - 1  Q-1:** D (Correct: D) = **4 marks**\n","- ‚úì **Zoology - 1  Q-2:** A (Correct: A) = **4 marks**\n","- ‚úì **Zoology - 1  Q-3:** D (Correct: D) = **4 marks**\n","- ‚úì **Zoology - 1  Q-4:** B (Correct: B) = **4 marks**\n","- ‚úì **Zoology - 1  Q-5:** D (Correct: D) = **4 marks**\n","- ‚úì **Zoology - 1  Q-6:** D (Correct: D) = **4 marks**\n","- ‚úì **Zoology - 1  Q-7:** D (Correct: D) = **4 marks**\n","- ‚úì **Zoology - 1  Q-8:** A (Correct: A) = **4 marks**\n","- ‚úì **Zoology - 1  Q-9:** A (Correct: A) = **4 marks**\n","- ‚úì **Zoology - 1  Q-10:** C (Correct: C) = **4 marks**\n","- ‚úì **Zoology - 1  Q-11:** B (Correct: B) = **4 marks**\n","- ‚úì **Zoology - 1  Q-12:** A (Correct: A) = **4 marks**\n","- ‚úì **Zoology - 1  Q-13:** C (Correct: C) = **4 marks**\n","- ‚úì **Zoology - 1  Q-14:** C (Correct: C) = **4 marks**\n","- ‚úì **Zoology - 1  Q-15:** A (Correct: A) = **4 marks**\n","- ‚úì **Zoology - 1  Q-16:** D (Correct: D) = **4 marks**\n","- ‚úì **Zoology - 1  Q-17:** B (Correct: B) = **4 marks**\n","- ‚úì **Zoology - 1  Q-18:** A (Correct: A) = **4 marks**\n","- ‚úì **Zoology - 2  Q-19:** B (Correct: B) = **4 marks**\n","- ‚úì **Zoology - 2  Q-20:** D (Correct: D) = **4 marks**\n","- ‚úì **Zoology - 2  Q-21:** C (Correct: C) = **4 marks**\n","- ‚úì **Zoology - 2  Q-22:** C (Correct: C) = **4 marks**\n","- ‚úì **Zoology - 2  Q-23:** D (Correct: D) = **4 marks**\n","- ‚úì **Zoology - 2  Q-24:** D (Correct: D) = **4 marks**\n","- ‚úì **Zoology - 2  Q-25:** A (Correct: A) = **4 marks**\n","- ‚úì **Zoology - 2  Q-26:** C (Correct: C) = **4 marks**\n","- ‚úì **Zoology - 2  Q-27:** B (Correct: B) = **4 marks**\n","- ‚úì **Zoology - 2  Q-28:** D (Correct: D) = **4 marks**\n","- ‚úì **Zoology - 2  Q-29:** C (Correct: C) = **4 marks**\n","- ‚úì **Zoology - 2  Q-30:** A (Correct: A) = **4 marks**\n","- ‚úì **Zoology - 2  Q-31:** A (Correct: A) = **4 marks**\n","- ‚úì **Zoology - 2  Q-32:** D (Correct: D) = **4 marks**\n","- ‚úì **Zoology - 2  Q-33:** B (Correct: B) = **4 marks**\n","- ‚úì **Zoology - 2  Q-34:** C (Correct: C) = **4 marks**\n","- ‚úì **Zoology - 2  Q-35:** D (Correct: D) = **4 marks**\n","- ‚úì **Zoology - 2  Q-36:** A (Correct: A) = **4 marks**\n","- ‚úì **Zoology - 2  Q-37:** B (Correct: B) = **4 marks**\n","- ‚úì **Zoology - 2  Q-38:** A (Correct: A) = **4 marks**\n","- ‚úì **Zoology - 2  Q-39:** C (Correct: C) = **4 marks**\n","- ‚úì **Zoology - 2  Q-40:** A (Correct: A) = **4 marks**\n","- ‚úì **Zoology - 2  Q-41:** C (Correct: C) = **4 marks**\n","- ‚óã **Zoology - 2  Q-42:** None (Correct: None) = **0 marks**\n","- ‚úì **Zoology - 2  Q-43:** A (Correct: A) = **4 marks**\n","- ‚úì **Zoology - 2  Q-44:** A (Correct: A) = **4 marks**\n","- ‚úì **Zoology - 2  Q-45:** D (Correct: D) = **4 marks**\n","- ‚úì **Zoology - 2  Q-46:** A (Correct: A) = **4 marks**\n","- ‚óã **Zoology - 2  Q-47:** None (Correct: None) = **0 marks**\n","- ‚óã **Zoology - 2  Q-48:** None (Correct: None) = **0 marks**\n","- ‚óã **Zoology - 2  Q-49:** None (Correct: None) = **0 marks**\n","- ‚óã **Zoology - 2  Q-50:** None (Correct: None) = **0 marks**\n"]}],"source":["if __name__ == \"__main__\":\n","    results = check_answers(\n","        input_omr = 'new1.jpg',\n","        solutions_json='solutions.json',\n","        omr_template = \"omr_template-2.json\",\n","        if_correct=4,\n","        if_wrong=-1,\n","        thresh_size=201,\n","        aspect_ratio_tolerance=1,\n","        check_orientation=True\n","        )\n","    if not isinstance(results, dict):\n","        print(results)\n","    else:\n","        display_markdown(Markdown(results))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":211},"executionInfo":{"elapsed":405,"status":"error","timestamp":1750178847549,"user":{"displayName":"Taanush abraham","userId":"16497560746847074205"},"user_tz":-330},"id":"5089K1EdQulQ","outputId":"df3a0b2e-8377-4799-fbfe-3c91e94f43c6"},"outputs":[{"output_type":"error","ename":"TypeError","evalue":"deskew_document() missing 1 required positional argument: 'osd'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-860268933>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mdeskewed_document\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeskew_document\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_image_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresh_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maspect_ratio_tolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdeskewed_document\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: deskew_document() missing 1 required positional argument: 'osd'"]}],"source":["import cProfile\n","import pstats\n","\n","# ... your existing code ...\n","\n","if __name__ == \"__main__\":\n","    input_image_path = 'test2.jpg'\n","\n","    thresh_size = 201\n","    aspect_ratio_tolerance = 0.1\n","\n","    profiler = cProfile.Profile()\n","    profiler.enable()\n","\n","    deskewed_document = deskew_document(input_image_path, thresh_size, aspect_ratio_tolerance)\n","\n","    if deskewed_document is not None:\n","        # ... rest of your main logic ...\n","        decoded_data = process_omr_with_template(deskewed_document, \"omr_template-1.json\")\n","\n","    profiler.disable()\n","    stats = pstats.Stats(profiler).sort_stats('cumtime')\n","    stats.print_stats(20) # Print top 20 functions by cumulative time"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1747909940012,"user":{"displayName":"Taanush abraham","userId":"16497560746847074205"},"user_tz":-330},"id":"FCPP_TrL8Ele","outputId":"e4fe8aeb-8340-4527-d7ca-a985858a4d02"},"outputs":[{"name":"stdout","output_type":"stream","text":["[None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None]\n"]}],"source":["answer_key = [\n","    3,  # 1\n","    2,  # 2\n","    2,  # 3\n","    4,  # 4\n","    4,  # 5\n","    1,  # 6\n","    1,  # 7\n","    3,  # 8\n","    4,  # 9\n","    4,  # 10\n","    2,  # 11\n","    2,  # 12\n","    2,  # 13\n","    3,  # 14\n","    4,  # 15\n","    2,  # 16\n","    2,  # 17\n","    3,  # 18\n","    2,  # 19\n","    3,  # 20\n","    2,  # 21\n","    2,  # 22\n","    4,  # 23\n","    3,  # 24\n","    1,  # 25\n","    2,  # 26\n","    2,  # 27\n","    4,  # 28\n","    2,  # 29\n","    3,  # 30\n","    3,  # 31\n","    2,  # 32\n","    4,  # 33\n","    1,  # 34\n","    2,  # 35\n","    3,  # 36\n","    4,  # 37\n","    4,  # 38\n","    3,  # 39\n","    4,  # 40\n","    1,  # 41\n","    1,  # 42\n","    1,  # 43\n","    1,  # 44\n","    1,  # 45\n","    2,  # 46\n","    1,  # 47\n","    2,  # 48\n","    2,  # 49\n","    2,  # 50\n","    2,  # 51\n","    4,  # 52\n","    2,  # 53\n","    3,  # 54\n","    2,  # 55\n","    1,  # 56\n","    3,  # 57\n","    4,  # 58\n","    2,  # 59\n","    1,  # 60\n","    4,  # 61\n","    3,  # 62\n","    2,  # 63\n","    3,  # 64\n","    1,  # 65\n","    1,  # 66\n","    2,  # 67\n","    2,  # 68\n","    1,  # 69\n","    4,  # 70\n","    1,  # 71\n","    4,  # 72\n","    2,  # 73\n","    3,  # 74\n","    1,  # 75\n","    2,  # 76\n","    1,  # 77\n","    1,  # 78\n","    1,  # 79\n","    1,  # 80\n","    3,  # 81\n","    1,  # 82\n","    2,  # 83\n","    1,  # 84\n","    2,  # 85\n","    1,  # 86\n","    2,  # 87\n","    2,  # 88\n","    3,  # 89\n","    1,  # 90\n","    1,  # 91\n","    1,  # 92\n","    2,  # 93\n","    1,  # 94\n","    4,  # 95\n","    4,  # 96\n","    3,  # 97\n","    1,  # 98\n","    4,  # 99\n","    3,  # 100\n","    3,  # 101\n","    1,  # 102\n","    4,  # 103\n","    3,  # 104\n","    2,  # 105\n","    1,  # 106\n","    2,  # 107\n","    1,  # 108\n","    4,  # 109\n","    2,  # 110\n","    1,  # 111\n","    3,  # 112\n","    1,  # 113\n","    1,  # 114\n","    1,  # 115\n","    2,  # 116\n","    1,  # 117\n","    3,  # 118\n","    4,  # 119\n","    3,  # 120\n","    1,  # 121\n","    4,  # 122\n","    2,  # 123\n","    3,  # 124\n","    1,  # 125\n","    3,  # 126\n","    4,  # 127\n","    1,  # 128\n","    4,  # 129\n","    4,  # 130\n","    2,  # 131\n","    3,  # 132\n","    1,  # 133\n","    1,  # 134\n","    4,  # 135\n","    1,  # 136\n","    4,  # 137\n","    2,  # 138\n","    3,  # 139\n","    3,  # 140\n","    3,  # 141\n","    1,  # 142\n","    3,  # 143\n","    1,  # 144\n","    3,  # 145\n","    2,  # 146\n","    4,  # 147\n","    1,  # 148\n","    1,  # 149\n","    3,  # 150\n","    4,  # 151\n","    1,  # 152\n","    4,  # 153\n","    2,  # 154\n","    4,  # 155\n","    4,  # 156\n","    4,  # 157\n","    1,  # 158\n","    1,  # 159\n","    3,  # 160\n","    2,  # 161\n","    1,  # 162\n","    3,  # 163\n","    3,  # 164\n","    1,  # 165\n","    4,  # 166\n","    2,  # 167\n","    1,  # 168\n","    2,  # 169\n","    4,  # 170\n","    3,  # 171\n","    3,  # 172\n","    4,  # 173\n","    4,  # 174\n","    1,  # 175\n","    3,  # 176\n","    2,  # 177\n","    2,  # 178\n","    3,  # 179\n","    1,  # 180\n","    1,  # 181\n","    4,  # 182\n","    2,  # 183\n","    2,  # 184\n","    4,  # 185\n","    1,  # 186\n","    4,  # 187\n","    3,  # 188\n","    4,  # 189\n","    1,  # 190\n","    3,  # 191\n","    1,  # 192\n","    1,  # 193\n","    4,  # 194\n","    3,  # 195\n","    1,  # 196\n","    1,  # 197\n","    4,  # 198\n","    1,  # 199\n","    3   # 200\n","]\n","for i in range(len(answer_key)):\n","    answer_key[i]=answer_key[i]\n","print(answers)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1747909947563,"user":{"displayName":"Taanush abraham","userId":"16497560746847074205"},"user_tz":-330},"id":"dcPtLFOmZW6u","outputId":"ef39fabf-1bc4-47cd-bc6f-32b85b67f317"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Total score: 0/200\n"]}],"source":["\n","score = 0\n","total_questions = min(len(answers), len(answer_key))\n","\n","for i in range(total_questions):\n","    if answers[i] is not None and answers[i] == answer_key[i]:\n","        score += 1  # or your marking scheme\n","\n","print(f\"\\nTotal score: {score}/{len(answer_key)}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":228},"executionInfo":{"elapsed":6,"status":"error","timestamp":1747909944692,"user":{"displayName":"Taanush abraham","userId":"16497560746847074205"},"user_tz":-330},"id":"LMWRQyvOZs3W","outputId":"fcc4a8d3-d1b6-4be8-b517-a8c02c7e3539"},"outputs":[{"ename":"NameError","evalue":"name 'options_map' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-2a342929d1b2>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manswer_key\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdetected_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptions_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdetected\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdetected\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdetected\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions_map\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"None\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mcorrect_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptions_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcorrect\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcorrect\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcorrect\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions_map\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"Invalid Key\"\u001b[0m \u001b[0;31m# Handle potential issue in answer_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Correct\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdetected\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdetected\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcorrect\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"Wrong\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Q{i+1}: Detected: {detected_str}, Correct: {correct_str} ‚Üí {status}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'options_map' is not defined"]}],"source":["for i in range(min(len(answers), len(answer_key))):\n","    detected = answers[i]\n","    correct = answer_key[i]\n","    detected_str = options_map[detected] if detected is not None and detected < len(options_map) else \"None\"\n","    correct_str = options_map[correct] if correct is not None and correct < len(options_map) else \"Invalid Key\" # Handle potential issue in answer_key\n","    status = \"Correct\" if detected is not None and detected == correct else \"Wrong\"\n","    print(f\"Q{i+1}: Detected: {detected_str}, Correct: {correct_str} ‚Üí {status}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1747900488207,"user":{"displayName":"Taanush abraham","userId":"16497560746847074205"},"user_tz":-330},"id":"JqgqNmoOZv3I","outputId":"d58a515b-712f-425c-c564-163590681bad"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Results saved to omr_results.json\n"]}],"source":["\n","\n","results = []\n","\n","for i in range(min(len(answers), len(answer_key))):\n","    detected = answers[i]\n","    correct = answer_key[i]\n","    results.append({\n","        'question': i+1,\n","        'detected_answer': options_map[detected] if detected is not None and detected < len(options_map) else None,\n","        'correct_answer': options_map[correct] if correct is not None and correct < len(options_map) else \"Invalid Key\",\n","        'status': \"Correct\" if detected is not None and detected == correct else \"Wrong\"\n","    })\n","\n","with open('omr_results.json', 'w') as f:\n","    json.dump(results, f, indent=4)\n","\n","print(\"\\nResults saved to omr_results.json\")\n"]}],"metadata":{"colab":{"provenance":[{"file_id":"1cONeWIvz16Ldlck7kEIHQ3fVgPwmX36L","timestamp":1750170265144},{"file_id":"1rHEgO8Y9cPz8R8w1FQmBrsBNYfP-UhSW","timestamp":1747916460536}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}